{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import glob\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "from scipy.io import wavfile as wav\n",
    "import os\n",
    "from datetime import datetime \n",
    "from sklearn import metrics \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "    nmfcc=40\n",
    "    hop_length = 512\n",
    "    n_fft = 1024\n",
    "    n_mels = 128\n",
    "    try:\n",
    "        y, sr = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        audio, _ = librosa.effects.trim(y)\n",
    "        S = librosa.feature.mfcc(audio, sr=sr, n_fft=n_fft, hop_length=hop_length, center=False, n_mfcc=nmfcc, fmin=0)\n",
    "        S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "        mfccsscaled = np.mean(S_DB.T,axis=0)   \n",
    "    except Exception:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "    return mfccsscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-80.0, -2.5677357, -80.0, -80.0, -80.0, -80.0...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-80.0, -1.000009, -80.0, -3.5282154, -51.5522...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-80.0, -0.9102828, -80.0, -4.7280188, -51.951...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-80.0, -1.4973112, -77.357445, -4.4096923, -4...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-80.0, -0.58883995, -80.0, -3.3096602, -45.63...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8727</th>\n",
       "      <td>[-80.0, -0.64906764, -80.0, -6.3651896, -75.83...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8728</th>\n",
       "      <td>[-80.0, -2.813218, -80.0, -4.689935, -80.0, -5...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8729</th>\n",
       "      <td>[-80.0, -1.5988646, -80.0, -6.2588015, -74.091...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8730</th>\n",
       "      <td>[-80.0, -0.66870856, -80.0, -6.298651, -80.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8731</th>\n",
       "      <td>[-80.0, -1.0094088, -80.0, -4.0532303, -72.861...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8732 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                feature  class_label\n",
       "0     [-80.0, -2.5677357, -80.0, -80.0, -80.0, -80.0...            3\n",
       "1     [-80.0, -1.000009, -80.0, -3.5282154, -51.5522...            2\n",
       "2     [-80.0, -0.9102828, -80.0, -4.7280188, -51.951...            2\n",
       "3     [-80.0, -1.4973112, -77.357445, -4.4096923, -4...            2\n",
       "4     [-80.0, -0.58883995, -80.0, -3.3096602, -45.63...            2\n",
       "...                                                 ...          ...\n",
       "8727  [-80.0, -0.64906764, -80.0, -6.3651896, -75.83...            1\n",
       "8728  [-80.0, -2.813218, -80.0, -4.689935, -80.0, -5...            1\n",
       "8729  [-80.0, -1.5988646, -80.0, -6.2588015, -74.091...            1\n",
       "8730  [-80.0, -0.66870856, -80.0, -6.298651, -80.0, ...            1\n",
       "8731  [-80.0, -1.0094088, -80.0, -4.0532303, -72.861...            1\n",
       "\n",
       "[8732 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Label filepath\n",
    "fulldatasetpath = 'UrbanSound8K/audio/'\n",
    "metadata = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "features = []\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    class_label = row[\"classID\"]\n",
    "    data = extract_features(file_name)\n",
    "    features.append([data, class_label])\n",
    "    \n",
    "## Convert to pandas dataframe\n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "featuresdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=6):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        ## x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs) \n",
    "        \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs) \n",
    "        \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  \n",
    "        ## (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  \n",
    "        ## (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  \n",
    "        ## (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  \n",
    "        ## (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    ## For calling multihead attention on embedded data and arranging it sequentially and adding other layers.\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    ## For preliminary token generation and embedding\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating audio data in the word domain to apply transformer\n",
    "featuresdf=featuresdf.dropna(axis=0)\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "X=X*10000\n",
    "min_X=-min([min(element) for element in X])\n",
    "x=X+min_X\n",
    "x=x.astype(int)\n",
    "max_len=max([max(element) for element in x])\n",
    "# Getting label size\n",
    "y = np.array(featuresdf.class_label.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8732 40\n",
      "(8732,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.1,shuffle=False)\n",
    "m,n=x.shape\n",
    "print(m,n)\n",
    "print(y.shape)\n",
    "x_train=x[0:int(m*9/10),:]\n",
    "x_test=x[int(m*9/10):m,:]\n",
    "y_train=y[0:int(m*9/10)]\n",
    "y_test=y[int(m*9/10):m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Changing data type for transformer layers\n",
    "m,n=x_test.shape\n",
    "\n",
    "## Converting form and reshaping\n",
    "TestX=x_test\n",
    "TestY=y_test\n",
    "testy=np.reshape(TestY,(m,))\n",
    "\n",
    "## Changing datatypes\n",
    "testx=np.empty((m,),object)\n",
    "for i in range (0,m):\n",
    "    testx[i]=list(int(v) for v in TestX[i])\n",
    "    testy[i]=testy[i].astype(int)\n",
    "\n",
    "## Converting Train Data and Getting size of data\n",
    "m,n=x_train.shape\n",
    "\n",
    "## Converting form and reshaping\n",
    "TrainX=x_train\n",
    "TrainY=y_train\n",
    "trainy=np.reshape(TrainY,(m,))\n",
    "\n",
    "## Changing datatypes\n",
    "trainx=np.empty((m,),object)\n",
    "for i in range (0,m):\n",
    "    trainx[i]=list(int(v) for v in TrainX[i])\n",
    "    trainy[i]=TrainY[i].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7858 Training sequences\n",
      "874 Validation sequences\n"
     ]
    }
   ],
   "source": [
    "vocab_size = max_len+1\n",
    "maxlen = 40\n",
    "print(len(trainx), \"Training sequences\")\n",
    "print(len(testx), \"Validation sequences\")\n",
    "\n",
    "## Converting to padded tensor sequence\n",
    "trainx = keras.preprocessing.sequence.pad_sequences(trainx,maxlen=maxlen)\n",
    "testx = keras.preprocessing.sequence.pad_sequences(testx,maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 40)]              0         \n",
      "_________________________________________________________________\n",
      "token_and_position_embedding (None, 40, 30)            24001230  \n",
      "_________________________________________________________________\n",
      "transformer_block (Transform (None, 40, 30)            5700      \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 40, 6)             546       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 40, 30)            210       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40, 30)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 20, 30)            0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20, 30)            930       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20, 30)            0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                310       \n",
      "=================================================================\n",
      "Total params: 24,011,716\n",
      "Trainable params: 24,011,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 30  ## Embedding size for each token\n",
    "num_heads = 6  ## Number of attention heads\n",
    "ff_dim = 30  ## Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "## Tokenizing input data with max dimension and embedding it\n",
    "inputs = layers.Input(shape=(maxlen,))\n",
    "#x = keras.Sequential()\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "\n",
    "## Adding Sequential layer to the embedded data and attention layers too.\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "\n",
    "## Add other layers\n",
    "x = layers.Conv1D(6,3,padding=\"same\")(x)\n",
    "x = layers.Dense(30, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.MaxPool1D(pool_size=2, strides=2)(x)\n",
    "x = layers.Dense(30, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dense(30, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(30, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(30, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "## Producing general softmax layer for classification\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "## Generating model\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "79/79 [==============================] - 20s 249ms/step - loss: 2.2991 - accuracy: 0.1199\n",
      "Epoch 2/5\n",
      "79/79 [==============================] - 18s 230ms/step - loss: 2.2788 - accuracy: 0.1144\n",
      "Epoch 3/5\n",
      "79/79 [==============================] - 20s 248ms/step - loss: 2.2714 - accuracy: 0.1173\n",
      "Epoch 4/5\n",
      "79/79 [==============================] - 18s 234ms/step - loss: 2.2572 - accuracy: 0.1251\n",
      "Epoch 5/5\n",
      "79/79 [==============================] - 18s 227ms/step - loss: 2.2119 - accuracy: 0.1588\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(trainx, trainy, batch_size=100, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Performance [2.1133389472961426, 0.21404936909675598]\n",
      "Testing Performanr [2.232602119445801, 0.19565217196941376]\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(trainx, trainy, verbose=0)\n",
    "print(\"Training Performance\",score)\n",
    "score = model.evaluate(testx, testy, verbose=0)\n",
    "print(\"Testing Performanr\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
