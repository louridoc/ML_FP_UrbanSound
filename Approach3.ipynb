{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification using Approach 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DESCRIPTION OF THE APPROACH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Libraries\n",
    "\n",
    "Before starting you will need to import the libraries that are needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import glob\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "from scipy.io import wavfile as wav\n",
    "import os\n",
    "from datetime import datetime \n",
    "import sklearn\n",
    "from sklearn import metrics \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=6):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        ## x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs) \n",
    "        \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs) \n",
    "        \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  \n",
    "        ## (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  \n",
    "        ## (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  \n",
    "        ## (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  \n",
    "        ## (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    ## For calling multihead attention on embedded data and arranging it sequentially and adding other layers.\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    ## For preliminary token generation and embedding\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#startTime=0.11\n",
    "#endTime=1.11\n",
    "#song = AudioSegment.from_wav('UrbanSound8K/audio/fold2/204773-3-9-1.wav')\n",
    "#extract = song[startTime:endTime]\n",
    "#print(extract)\n",
    "#extract.export('Extract',format='mp3')\n",
    "#audio,sample_rate=librosa.load('UrbanSound8K/audio/fold2/204773-3-9-1.wav')\n",
    "#nmfcc=20\n",
    "#mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=nmfcc)\n",
    "#mfccs = sklearn.preprocessing.scale(mfccs, axis=1)\n",
    "#arr=mfccs\n",
    "#print(arr.shape)\n",
    "#new_arr = ((arr - arr.min()) * (1/(arr.max() - arr.min()) * 100000)).astype(int)\n",
    "#new_arr=np.reshape(new_arr, (nmfcc*11,))\n",
    "#print(new_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccsscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  n_fft, y.shape[-1]\n",
      "C:\\Users\\chris\\anaconda3\\lib\\site-packages\\librosa\\core\\spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  n_fft, y.shape[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                feature  class_label\n",
      "0     [-215.79301, 71.66612, -131.81377, -52.09133, ...            3\n",
      "1     [-424.68677, 110.56227, -54.148235, 62.01074, ...            2\n",
      "2     [-459.56467, 122.800354, -47.92471, 53.265697,...            2\n",
      "3     [-414.55377, 102.896904, -36.66495, 54.18041, ...            2\n",
      "4     [-447.397, 115.0954, -53.809113, 61.60859, 1.6...            2\n",
      "...                                                 ...          ...\n",
      "8727  [-399.2257, 136.81902, -51.964222, 37.02399, -...            1\n",
      "8728  [-346.72733, 87.48847, -46.265022, 52.748833, ...            1\n",
      "8729  [-304.61316, 112.6199, -47.161945, 37.00349, -...            1\n",
      "8730  [-344.71423, 126.75813, -56.17717, 36.070927, ...            1\n",
      "8731  [-315.93384, 95.67589, -38.047768, 47.50074, -...            1\n",
      "\n",
      "[8732 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "fulldatasetpath = 'UrbanSound8K/audio/'\n",
    "metadata = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "features = []\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    class_label = row[\"classID\"]\n",
    "    data = extract_features(file_name)\n",
    "    features.append([data, class_label])\n",
    "    \n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "print(featuresdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104338845\n",
      "[[55124989 83870903 63522914 ... 76536014 76615704 76739729]\n",
      " [34235614 87760517 71289467 ... 76766031 76635793 76761442]\n",
      " [30747824 88984326 71911819 ... 76926832 76858952 76620659]\n",
      " ...\n",
      " [46242974 87966281 71988096 ... 76400932 76975348 77471480]\n",
      " [42232867 89380104 71086573 ... 75924064 76526383 77287832]\n",
      " [45110906 86271879 72899514 ... 76762048 75557914 76107755]] (8732, 40)\n",
      "[3 2 2 ... 1 1 1] (8732,)\n"
     ]
    }
   ],
   "source": [
    "featuresdf=featuresdf.dropna(axis=0)\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "#X = sklearn.preprocessing.scale(X)\n",
    "#x = ((X - X.min()) * (1/(X.max() - X.min()) * 100000)).astype(int)\n",
    "#max_len=max([max(element) for element in x])\n",
    "#print(x)\n",
    "#y = np.array(featuresdf.class_label.tolist())\n",
    "#print(y)\n",
    "X=X*100000\n",
    "min_X=-min([min(element) for element in X])\n",
    "x=X+min_X\n",
    "x=x.astype(int)\n",
    "max_len=max([max(element) for element in x])\n",
    "print(max_len)\n",
    "# Getting label size\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "print(x,x.shape)\n",
    "print(y,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2882 40\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'int'>\n",
      "<class 'list'>\n",
      "<class 'numpy.int32'>\n",
      "<class 'numpy.ndarray'>\n",
      "5850 40\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'int'>\n",
      "<class 'list'>\n",
      "<class 'numpy.int32'>\n",
      "<class 'numpy.ndarray'>\n",
      "(5850,) (5850,) (2882,) (2882,)\n"
     ]
    }
   ],
   "source": [
    "m,n=x_test.shape\n",
    "print(m,n)\n",
    "\n",
    "## Converting form and reshaping\n",
    "TestX=x_test\n",
    "TestY=y_test\n",
    "testy=np.reshape(TestY,(m,))\n",
    "\n",
    "## Changing datatypes\n",
    "testx=np.empty((m,),object)\n",
    "for i in range (0,m):\n",
    "    testx[i]=list(int(v) for v in TestX[i])\n",
    "    testy[i]=testy[i].astype(int)\n",
    "\n",
    "## Printing data-types - relevant to transformer input\n",
    "print(type(testx))\n",
    "print(type(testx[m-1][n-1]))\n",
    "print(type(testx[m-1]))\n",
    "print(type(testy[m-1]))\n",
    "print(type(testy))\n",
    "\n",
    "## Converting Train Data and Getting size of data\n",
    "m,n=x_train.shape\n",
    "print(m,n)\n",
    "\n",
    "## Converting form and reshaping\n",
    "TrainX=x_train\n",
    "TrainY=y_train\n",
    "trainy=np.reshape(TrainY,(m,))\n",
    "\n",
    "## Changing datatypes\n",
    "trainx=np.empty((m,),object)\n",
    "for i in range (0,m):\n",
    "    trainx[i]=list(int(v) for v in TrainX[i])\n",
    "    trainy[i]=TrainY[i].astype(int)\n",
    "    \n",
    "## Printing data-types - relevant to transformer input\n",
    "print(type(trainx))\n",
    "print(type(trainx[m-1][n-1]))\n",
    "print(type(trainx[m-1]))\n",
    "print(type(trainy[m-1]))\n",
    "print(type(trainy))\n",
    "print(trainx.shape,trainy.shape,testx.shape,testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5850 Training sequences\n",
      "2882 Validation sequences\n",
      "(5850, 40) (5850,) (2882, 40) (2882,)\n",
      "[[62137597 78335727 72880427 ... 77052909 76297692 77056225]\n",
      " [56190113 96227093 76519287 ... 76470681 76472803 77059141]\n",
      " [57354196 90859410 72696932 ... 76759726 76683174 76637231]\n",
      " ...\n",
      " [18281848 92145918 70166513 ... 76385245 76937164 76049535]\n",
      " [66350048 93174070 72786761 ... 76973658 77026353 76877930]\n",
      " [42899530 86940032 73994583 ... 76712891 76271752 76351661]] [7 9 3 ... 8 5 8] [[58395013 87664977 64456540 ... 76694969 76592161 76925777]\n",
      " [52305891 94894248 73165505 ... 76648285 76396553 76633610]\n",
      " [15201312 90125158 75244779 ... 76230071 76791889 76514939]\n",
      " ...\n",
      " [34846868 93652304 68048023 ... 76506201 76687604 76680986]\n",
      " [58320698 87138247 74485121 ... 76733707 76708008 76718180]\n",
      " [47970864 97041497 65043084 ... 76516383 76899214 77234400]] [2 3 8 ... 4 9 5]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = max_len+1\n",
    "maxlen = 40\n",
    "print(len(trainx), \"Training sequences\")\n",
    "print(len(testx), \"Validation sequences\")\n",
    "\n",
    "## Converting to padded tensor sequence\n",
    "trainx = keras.preprocessing.sequence.pad_sequences(trainx,maxlen=maxlen)\n",
    "testx = keras.preprocessing.sequence.pad_sequences(testx,maxlen=maxlen)\n",
    "print(trainx.shape,trainy.shape,testx.shape,testy.shape)\n",
    "print(trainx,trainy,testx,testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chris\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method TokenAndPositionEmbedding.call of <__main__.TokenAndPositionEmbedding object at 0x000002803D0F6C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenAndPositionEmbedding.call of <__main__.TokenAndPositionEmbedding object at 0x000002803D0F6C08>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method TokenAndPositionEmbedding.call of <__main__.TokenAndPositionEmbedding object at 0x000002803D0F6C08>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TokenAndPositionEmbedding.call of <__main__.TokenAndPositionEmbedding object at 0x000002803D0F6C08>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From C:\\Users\\chris\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method TransformerBlock.call of <__main__.TransformerBlock object at 0x000002803D0F6A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerBlock.call of <__main__.TransformerBlock object at 0x000002803D0F6A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method TransformerBlock.call of <__main__.TransformerBlock object at 0x000002803D0F6A48>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method TransformerBlock.call of <__main__.TransformerBlock object at 0x000002803D0F6A48>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in converted code:\n\n\n    TypeError: call() missing 1 required positional argument: 'training'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-81b51ad91f2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0membedding_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtransformer_block\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTransformerBlock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mff_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer_block\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGlobalAveragePooling1D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\chris\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    632\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m                   \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\chris\\anaconda3\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    147\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ag_error_metadata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in converted code:\n\n\n    TypeError: call() missing 1 required positional argument: 'training'\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 30  ## Embedding size for each token\n",
    "num_heads = 6  ## Number of attention heads\n",
    "ff_dim = 30  ## Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(trainx, trainy, batch_size=100, epochs=100, validation_data=(testx,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
