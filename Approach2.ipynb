{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\chris\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 6985 samples, validate on 1747 samples\n",
      "Epoch 1/100\n",
      "6985/6985 [==============================] - 1s 87us/step - loss: 8.4859 - accuracy: 0.1983 - val_loss: 2.1263 - val_accuracy: 0.2376\n",
      "Epoch 2/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 2.2244 - accuracy: 0.2634 - val_loss: 2.0446 - val_accuracy: 0.2811\n",
      "Epoch 3/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 2.0277 - accuracy: 0.3057 - val_loss: 1.8436 - val_accuracy: 0.3692\n",
      "Epoch 4/100\n",
      "6985/6985 [==============================] - 0s 59us/step - loss: 1.8536 - accuracy: 0.3556 - val_loss: 1.6354 - val_accuracy: 0.4585\n",
      "Epoch 5/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 1.7056 - accuracy: 0.4010 - val_loss: 1.4708 - val_accuracy: 0.5426\n",
      "Epoch 6/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 1.6089 - accuracy: 0.4448 - val_loss: 1.3543 - val_accuracy: 0.5615\n",
      "Epoch 7/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 1.5133 - accuracy: 0.4763 - val_loss: 1.2702 - val_accuracy: 0.5999\n",
      "Epoch 8/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 1.4404 - accuracy: 0.5018 - val_loss: 1.1964 - val_accuracy: 0.6182\n",
      "Epoch 9/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 1.3620 - accuracy: 0.5380 - val_loss: 1.1390 - val_accuracy: 0.6514\n",
      "Epoch 10/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 1.2994 - accuracy: 0.5572 - val_loss: 1.0616 - val_accuracy: 0.6520\n",
      "Epoch 11/100\n",
      "6985/6985 [==============================] - 0s 59us/step - loss: 1.2540 - accuracy: 0.5727 - val_loss: 1.0076 - val_accuracy: 0.6634\n",
      "Epoch 12/100\n",
      "6985/6985 [==============================] - 0s 60us/step - loss: 1.1902 - accuracy: 0.5987 - val_loss: 0.9876 - val_accuracy: 0.6857\n",
      "Epoch 13/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 1.1517 - accuracy: 0.6112 - val_loss: 0.9186 - val_accuracy: 0.7195\n",
      "Epoch 14/100\n",
      "6985/6985 [==============================] - 0s 60us/step - loss: 1.1141 - accuracy: 0.6252 - val_loss: 0.9168 - val_accuracy: 0.7367\n",
      "Epoch 15/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 1.0666 - accuracy: 0.6338 - val_loss: 0.8328 - val_accuracy: 0.7459\n",
      "Epoch 16/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 1.0490 - accuracy: 0.6447 - val_loss: 0.8475 - val_accuracy: 0.7396\n",
      "Epoch 17/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 1.0313 - accuracy: 0.6507 - val_loss: 0.8443 - val_accuracy: 0.7390\n",
      "Epoch 18/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.9959 - accuracy: 0.6597 - val_loss: 0.8038 - val_accuracy: 0.7613\n",
      "Epoch 19/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.9739 - accuracy: 0.6727 - val_loss: 0.7903 - val_accuracy: 0.7630\n",
      "Epoch 20/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.9366 - accuracy: 0.6885 - val_loss: 0.7391 - val_accuracy: 0.7750\n",
      "Epoch 21/100\n",
      "6985/6985 [==============================] - 0s 59us/step - loss: 0.9358 - accuracy: 0.6800 - val_loss: 0.7393 - val_accuracy: 0.7602\n",
      "Epoch 22/100\n",
      "6985/6985 [==============================] - 0s 59us/step - loss: 0.9072 - accuracy: 0.6913 - val_loss: 0.7234 - val_accuracy: 0.7802\n",
      "Epoch 23/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.8910 - accuracy: 0.6956 - val_loss: 0.7105 - val_accuracy: 0.7911\n",
      "Epoch 24/100\n",
      "6985/6985 [==============================] - 0s 64us/step - loss: 0.8539 - accuracy: 0.7078 - val_loss: 0.6826 - val_accuracy: 0.7962\n",
      "Epoch 25/100\n",
      "6985/6985 [==============================] - 0s 65us/step - loss: 0.8480 - accuracy: 0.7107 - val_loss: 0.6869 - val_accuracy: 0.8054\n",
      "Epoch 26/100\n",
      "6985/6985 [==============================] - 0s 60us/step - loss: 0.8409 - accuracy: 0.7147 - val_loss: 0.6493 - val_accuracy: 0.8031\n",
      "Epoch 27/100\n",
      "6985/6985 [==============================] - 0s 59us/step - loss: 0.8246 - accuracy: 0.7221 - val_loss: 0.6434 - val_accuracy: 0.8077\n",
      "Epoch 28/100\n",
      "6985/6985 [==============================] - 0s 59us/step - loss: 0.8149 - accuracy: 0.7230 - val_loss: 0.6328 - val_accuracy: 0.8117\n",
      "Epoch 29/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.7826 - accuracy: 0.7326 - val_loss: 0.6200 - val_accuracy: 0.8048\n",
      "Epoch 30/100\n",
      "6985/6985 [==============================] - 0s 63us/step - loss: 0.7906 - accuracy: 0.7283 - val_loss: 0.6322 - val_accuracy: 0.8134\n",
      "Epoch 31/100\n",
      "6985/6985 [==============================] - 0s 62us/step - loss: 0.7651 - accuracy: 0.7460 - val_loss: 0.6059 - val_accuracy: 0.8197\n",
      "Epoch 32/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.7814 - accuracy: 0.7383 - val_loss: 0.6060 - val_accuracy: 0.8248\n",
      "Epoch 33/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.7588 - accuracy: 0.7476 - val_loss: 0.6148 - val_accuracy: 0.8197\n",
      "Epoch 34/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.7456 - accuracy: 0.7513 - val_loss: 0.5909 - val_accuracy: 0.8174\n",
      "Epoch 35/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.7341 - accuracy: 0.7509 - val_loss: 0.5689 - val_accuracy: 0.8248\n",
      "Epoch 36/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.7533 - accuracy: 0.7447 - val_loss: 0.5898 - val_accuracy: 0.8191\n",
      "Epoch 37/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.7065 - accuracy: 0.7571 - val_loss: 0.5544 - val_accuracy: 0.8271\n",
      "Epoch 38/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.7182 - accuracy: 0.7601 - val_loss: 0.5818 - val_accuracy: 0.8277\n",
      "Epoch 39/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.7118 - accuracy: 0.7596 - val_loss: 0.5452 - val_accuracy: 0.8414\n",
      "Epoch 40/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.7056 - accuracy: 0.7619 - val_loss: 0.5692 - val_accuracy: 0.8248\n",
      "Epoch 41/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.7057 - accuracy: 0.7586 - val_loss: 0.5486 - val_accuracy: 0.8409\n",
      "Epoch 42/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.6911 - accuracy: 0.7676 - val_loss: 0.5244 - val_accuracy: 0.8489\n",
      "Epoch 43/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.6868 - accuracy: 0.7709 - val_loss: 0.5551 - val_accuracy: 0.8454\n",
      "Epoch 44/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.6663 - accuracy: 0.7728 - val_loss: 0.5410 - val_accuracy: 0.8414\n",
      "Epoch 45/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.6506 - accuracy: 0.7817 - val_loss: 0.5336 - val_accuracy: 0.8403\n",
      "Epoch 46/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.6556 - accuracy: 0.7802 - val_loss: 0.5186 - val_accuracy: 0.8351\n",
      "Epoch 47/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.6650 - accuracy: 0.7772 - val_loss: 0.5196 - val_accuracy: 0.8380\n",
      "Epoch 48/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.6470 - accuracy: 0.7790 - val_loss: 0.4981 - val_accuracy: 0.8523\n",
      "Epoch 49/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.6622 - accuracy: 0.7738 - val_loss: 0.5288 - val_accuracy: 0.8403\n",
      "Epoch 50/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.6524 - accuracy: 0.7825 - val_loss: 0.5081 - val_accuracy: 0.8397\n",
      "Epoch 51/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.6590 - accuracy: 0.7772 - val_loss: 0.5036 - val_accuracy: 0.8495\n",
      "Epoch 52/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.6402 - accuracy: 0.7873 - val_loss: 0.5107 - val_accuracy: 0.8546\n",
      "Epoch 53/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.6284 - accuracy: 0.7884 - val_loss: 0.5193 - val_accuracy: 0.8512\n",
      "Epoch 54/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.6266 - accuracy: 0.7941 - val_loss: 0.4857 - val_accuracy: 0.8529\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.6219 - accuracy: 0.7931 - val_loss: 0.5027 - val_accuracy: 0.8626\n",
      "Epoch 56/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.6226 - accuracy: 0.7940 - val_loss: 0.4927 - val_accuracy: 0.8609\n",
      "Epoch 57/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.6288 - accuracy: 0.7877 - val_loss: 0.5026 - val_accuracy: 0.8540\n",
      "Epoch 58/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.6352 - accuracy: 0.7873 - val_loss: 0.5092 - val_accuracy: 0.8477\n",
      "Epoch 59/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.6263 - accuracy: 0.7943 - val_loss: 0.4823 - val_accuracy: 0.8609\n",
      "Epoch 60/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.6102 - accuracy: 0.7917 - val_loss: 0.5049 - val_accuracy: 0.8546\n",
      "Epoch 61/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.6139 - accuracy: 0.7900 - val_loss: 0.4688 - val_accuracy: 0.8620\n",
      "Epoch 62/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5924 - accuracy: 0.7997 - val_loss: 0.4715 - val_accuracy: 0.8643\n",
      "Epoch 63/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5913 - accuracy: 0.7969 - val_loss: 0.4809 - val_accuracy: 0.8620\n",
      "Epoch 64/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.6116 - accuracy: 0.7977 - val_loss: 0.4612 - val_accuracy: 0.8661\n",
      "Epoch 65/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.5922 - accuracy: 0.8013 - val_loss: 0.4961 - val_accuracy: 0.8472\n",
      "Epoch 66/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5977 - accuracy: 0.7969 - val_loss: 0.4833 - val_accuracy: 0.8535\n",
      "Epoch 67/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5849 - accuracy: 0.8009 - val_loss: 0.4786 - val_accuracy: 0.8666\n",
      "Epoch 68/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5990 - accuracy: 0.8040 - val_loss: 0.4712 - val_accuracy: 0.8535\n",
      "Epoch 69/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5851 - accuracy: 0.8026 - val_loss: 0.4677 - val_accuracy: 0.8592\n",
      "Epoch 70/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.5754 - accuracy: 0.8062 - val_loss: 0.4669 - val_accuracy: 0.8615\n",
      "Epoch 71/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5981 - accuracy: 0.8014 - val_loss: 0.4866 - val_accuracy: 0.8598\n",
      "Epoch 72/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.5817 - accuracy: 0.8076 - val_loss: 0.4564 - val_accuracy: 0.8672\n",
      "Epoch 73/100\n",
      "6985/6985 [==============================] - 0s 59us/step - loss: 0.5734 - accuracy: 0.8062 - val_loss: 0.4700 - val_accuracy: 0.8626\n",
      "Epoch 74/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5687 - accuracy: 0.8023 - val_loss: 0.4553 - val_accuracy: 0.8689\n",
      "Epoch 75/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5474 - accuracy: 0.8146 - val_loss: 0.4501 - val_accuracy: 0.8775\n",
      "Epoch 76/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5721 - accuracy: 0.8052 - val_loss: 0.4641 - val_accuracy: 0.8592\n",
      "Epoch 77/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.5757 - accuracy: 0.8122 - val_loss: 0.4543 - val_accuracy: 0.8683\n",
      "Epoch 78/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.5516 - accuracy: 0.8103 - val_loss: 0.4502 - val_accuracy: 0.8683\n",
      "Epoch 79/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.5593 - accuracy: 0.8146 - val_loss: 0.4525 - val_accuracy: 0.8672\n",
      "Epoch 80/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.5547 - accuracy: 0.8126 - val_loss: 0.4509 - val_accuracy: 0.8712\n",
      "Epoch 81/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.5468 - accuracy: 0.8219 - val_loss: 0.4377 - val_accuracy: 0.8695\n",
      "Epoch 82/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5623 - accuracy: 0.8080 - val_loss: 0.4529 - val_accuracy: 0.8615\n",
      "Epoch 83/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5553 - accuracy: 0.8155 - val_loss: 0.4671 - val_accuracy: 0.8535\n",
      "Epoch 84/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.5787 - accuracy: 0.8040 - val_loss: 0.4471 - val_accuracy: 0.8643\n",
      "Epoch 85/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.5457 - accuracy: 0.8193 - val_loss: 0.4462 - val_accuracy: 0.8683\n",
      "Epoch 86/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5514 - accuracy: 0.8105 - val_loss: 0.4330 - val_accuracy: 0.8695\n",
      "Epoch 87/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5394 - accuracy: 0.8199 - val_loss: 0.4476 - val_accuracy: 0.8724\n",
      "Epoch 88/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5677 - accuracy: 0.8150 - val_loss: 0.4361 - val_accuracy: 0.8752\n",
      "Epoch 89/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.5339 - accuracy: 0.8189 - val_loss: 0.4366 - val_accuracy: 0.8701\n",
      "Epoch 90/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.5334 - accuracy: 0.8206 - val_loss: 0.4312 - val_accuracy: 0.8735\n",
      "Epoch 91/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.5356 - accuracy: 0.8219 - val_loss: 0.4252 - val_accuracy: 0.8701\n",
      "Epoch 92/100\n",
      "6985/6985 [==============================] - 0s 58us/step - loss: 0.5431 - accuracy: 0.8142 - val_loss: 0.4406 - val_accuracy: 0.8678\n",
      "Epoch 93/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5248 - accuracy: 0.8235 - val_loss: 0.4348 - val_accuracy: 0.8724\n",
      "Epoch 94/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5433 - accuracy: 0.8139 - val_loss: 0.4407 - val_accuracy: 0.8741\n",
      "Epoch 95/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.5277 - accuracy: 0.8196 - val_loss: 0.4399 - val_accuracy: 0.8649\n",
      "Epoch 96/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.5224 - accuracy: 0.8265 - val_loss: 0.4375 - val_accuracy: 0.8746\n",
      "Epoch 97/100\n",
      "6985/6985 [==============================] - 0s 55us/step - loss: 0.5194 - accuracy: 0.8222 - val_loss: 0.4279 - val_accuracy: 0.8815\n",
      "Epoch 98/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.5511 - accuracy: 0.8178 - val_loss: 0.4376 - val_accuracy: 0.8764\n",
      "Epoch 99/100\n",
      "6985/6985 [==============================] - 0s 57us/step - loss: 0.5380 - accuracy: 0.8236 - val_loss: 0.4520 - val_accuracy: 0.8701\n",
      "Epoch 100/100\n",
      "6985/6985 [==============================] - 0s 56us/step - loss: 0.5367 - accuracy: 0.8200 - val_loss: 0.4290 - val_accuracy: 0.8758\n",
      "Training completed in time:  0:00:40.682622\n",
      "train accuracy: [0.2650296589072978, 0.9285612106323242]\n",
      "test accuracy: [0.42897661264855724, 0.875787079334259]\n"
     ]
    }
   ],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "from scipy.io import wavfile as wav\n",
    "import os\n",
    "from datetime import datetime \n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "#### Dependencies ####\n",
    "\n",
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccsscaled\n",
    "\n",
    "# Set the path to the full UrbanSound dataset \n",
    "fulldatasetpath = 'UrbanSound8K/audio/'\n",
    "\n",
    "metadata = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "\n",
    "features = []\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "    \n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    \n",
    "    class_label = row[\"class\"]\n",
    "    data = extract_features(file_name)\n",
    "    \n",
    "    features.append([data, class_label])\n",
    "    \n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "\n",
    "# Convert features and corresponding classification labels into numpy arrays\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "\n",
    "# Encode the classification labels\n",
    "le = LabelEncoder()\n",
    "yy = to_categorical(le.fit_transform(y))\n",
    "\n",
    "# split the dataset \n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, yy, test_size=0.2, random_state = 42)\n",
    "\n",
    "num_labels = yy.shape[1]\n",
    "filter_size = 2\n",
    "\n",
    "# Construct model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(256, input_shape=(40,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "num_epochs = 100\n",
    "num_batch_size = 32\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(x_test, y_test), verbose=1)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "\n",
    "print(\"Training completed in time: \", duration)\n",
    "\n",
    "score = model.evaluate(x_train, y_train, verbose=0)\n",
    "print('train accuracy: {}'.format(score))\n",
    "# experiment.log_metric(\"train_acc\", score)\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('test accuracy: {}'.format(score))\n",
    "# experiment.log_metric(\"val_acc\", score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
