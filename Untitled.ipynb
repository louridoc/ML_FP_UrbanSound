{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import glob\n",
    "from scipy.io import wavfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib as plt\n",
    "import matplotlib.pyplot as plt\n",
    "import struct\n",
    "from scipy.io import wavfile as wav\n",
    "import os\n",
    "from datetime import datetime \n",
    "import sklearn\n",
    "from sklearn import metrics \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils, to_categorical\n",
    "from keras.callbacks import ModelCheckpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadSelfAttention(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads=6):\n",
    "        super(MultiHeadSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        if embed_dim % num_heads != 0:\n",
    "            raise ValueError(\n",
    "                f\"embedding dimension = {embed_dim} should be divisible by number of heads = {num_heads}\"\n",
    "            )\n",
    "        self.projection_dim = embed_dim // num_heads\n",
    "        self.query_dense = layers.Dense(embed_dim)\n",
    "        self.key_dense = layers.Dense(embed_dim)\n",
    "        self.value_dense = layers.Dense(embed_dim)\n",
    "        self.combine_heads = layers.Dense(embed_dim)\n",
    "\n",
    "    def attention(self, query, key, value):\n",
    "        score = tf.matmul(query, key, transpose_b=True)\n",
    "        dim_key = tf.cast(tf.shape(key)[-1], tf.float32)\n",
    "        scaled_score = score / tf.math.sqrt(dim_key)\n",
    "        weights = tf.nn.softmax(scaled_score, axis=-1)\n",
    "        output = tf.matmul(weights, value)\n",
    "        return output, weights\n",
    "\n",
    "    def separate_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.projection_dim))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        ## x.shape = [batch_size, seq_len, embedding_dim]\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        query = self.query_dense(inputs)\n",
    "        \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        key = self.key_dense(inputs) \n",
    "        \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        value = self.value_dense(inputs) \n",
    "        \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        query = self.separate_heads(\n",
    "            query, batch_size\n",
    "        )  \n",
    "        ## (batch_size, num_heads, seq_len, projection_dim)\n",
    "        key = self.separate_heads(\n",
    "            key, batch_size\n",
    "        )  \n",
    "        ## (batch_size, num_heads, seq_len, projection_dim)\n",
    "        value = self.separate_heads(\n",
    "            value, batch_size\n",
    "        )  \n",
    "        ## (batch_size, num_heads, seq_len, projection_dim)\n",
    "        attention, weights = self.attention(query, key, value)\n",
    "        attention = tf.transpose(\n",
    "            attention, perm=[0, 2, 1, 3]\n",
    "        )  \n",
    "        ## (batch_size, seq_len, num_heads, projection_dim)\n",
    "        concat_attention = tf.reshape(\n",
    "            attention, (batch_size, -1, self.embed_dim)\n",
    "        )  \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        output = self.combine_heads(\n",
    "            concat_attention\n",
    "        )  \n",
    "        ## (batch_size, seq_len, embed_dim)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    ## For calling multihead attention on embedded data and arranging it sequentially and adding other layers.\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.att = MultiHeadSelfAttention(embed_dim, num_heads)\n",
    "        self.ffn = keras.Sequential(\n",
    "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenAndPositionEmbedding(layers.Layer):\n",
    "    ## For preliminary token generation and embedding\n",
    "    def __init__(self, maxlen, vocab_size, embed_dim):\n",
    "        super(TokenAndPositionEmbedding, self).__init__()\n",
    "        self.token_emb = layers.Embedding(input_dim=vocab_size, output_dim=embed_dim)\n",
    "        self.pos_emb = layers.Embedding(input_dim=maxlen, output_dim=embed_dim)\n",
    "\n",
    "    def call(self, x):\n",
    "        maxlen = tf.shape(x)[-1]\n",
    "        positions = tf.range(start=0, limit=maxlen, delta=1)\n",
    "        positions = self.pos_emb(positions)\n",
    "        x = self.token_emb(x)\n",
    "        return x + positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#startTime=0.11\n",
    "#endTime=1.11\n",
    "#song = AudioSegment.from_wav('UrbanSound8K/audio/fold2/204773-3-9-1.wav')\n",
    "#extract = song[startTime:endTime]\n",
    "#print(extract)\n",
    "#extract.export('Extract',format='mp3')\n",
    "#audio,sample_rate=librosa.load('UrbanSound8K/audio/fold2/204773-3-9-1.wav')\n",
    "#nmfcc=20\n",
    "#mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=nmfcc)\n",
    "#mfccs = sklearn.preprocessing.scale(mfccs, axis=1)\n",
    "#arr=mfccs\n",
    "#print(arr.shape)\n",
    "#new_arr = ((arr - arr.min()) * (1/(arr.max() - arr.min()) * 100000)).astype(int)\n",
    "#new_arr=np.reshape(new_arr, (nmfcc*11,))\n",
    "#print(new_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_name):\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "        mfccsscaled = np.mean(mfccs.T,axis=0)\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "     \n",
    "    return mfccsscaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python38\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
      "  warnings.warn(\n",
      "c:\\python38\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
      "  warnings.warn(\n",
      "c:\\python38\\lib\\site-packages\\librosa\\core\\spectrum.py:222: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                feature  class_label\n",
      "0     [-215.79301, 71.66612, -131.81377, -52.091335,...            3\n",
      "1     [-424.68677, 110.56227, -54.148235, 62.01074, ...            2\n",
      "2     [-459.56467, 122.800354, -47.92471, 53.265697,...            2\n",
      "3     [-414.55377, 102.896904, -36.66495, 54.18041, ...            2\n",
      "4     [-447.397, 115.0954, -53.809113, 61.60859, 1.6...            2\n",
      "...                                                 ...          ...\n",
      "8727  [-399.2257, 136.81903, -51.964222, 37.02399, -...            1\n",
      "8728  [-346.72733, 87.48847, -46.265022, 52.748833, ...            1\n",
      "8729  [-304.61316, 112.6199, -47.161945, 37.00349, -...            1\n",
      "8730  [-344.71423, 126.75813, -56.17717, 36.070927, ...            1\n",
      "8731  [-315.93384, 95.67589, -38.047768, 47.50074, -...            1\n",
      "\n",
      "[8732 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "fulldatasetpath = 'UrbanSound8K/audio/'\n",
    "metadata = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
    "features = []\n",
    "\n",
    "for index, row in metadata.iterrows():\n",
    "    file_name = os.path.join(os.path.abspath(fulldatasetpath),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
    "    class_label = row[\"classID\"]\n",
    "    data = extract_features(file_name)\n",
    "    features.append([data, class_label])\n",
    "    \n",
    "# Convert into a Panda dataframe \n",
    "featuresdf = pd.DataFrame(features, columns=['feature','class_label'])\n",
    "print(featuresdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104338845\n",
      "[[55124989 83870903 63522914 ... 76536014 76615704 76739729]\n",
      " [34235614 87760517 71289467 ... 76766031 76635793 76761442]\n",
      " [30747824 88984326 71911819 ... 76926832 76858952 76620659]\n",
      " ...\n",
      " [46242974 87966281 71988096 ... 76400932 76975348 77471480]\n",
      " [42232867 89380104 71086573 ... 75924064 76526383 77287832]\n",
      " [45110906 86271879 72899514 ... 76762048 75557914 76107755]] (8732, 40)\n",
      "[3 2 2 ... 1 1 1] (8732,)\n"
     ]
    }
   ],
   "source": [
    "featuresdf=featuresdf.dropna(axis=0)\n",
    "X = np.array(featuresdf.feature.tolist())\n",
    "#X = sklearn.preprocessing.scale(X)\n",
    "#x = ((X - X.min()) * (1/(X.max() - X.min()) * 100000)).astype(int)\n",
    "#max_len=max([max(element) for element in x])\n",
    "#print(x)\n",
    "#y = np.array(featuresdf.class_label.tolist())\n",
    "#print(y)\n",
    "X=X*100000\n",
    "min_X=-min([min(element) for element in X])\n",
    "x=X+min_X\n",
    "x=x.astype(int)\n",
    "max_len=max([max(element) for element in x])\n",
    "print(max_len)\n",
    "# Getting label size\n",
    "y = np.array(featuresdf.class_label.tolist())\n",
    "print(x,x.shape)\n",
    "print(y,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2882 40\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'int'>\n",
      "<class 'list'>\n",
      "<class 'numpy.int32'>\n",
      "<class 'numpy.ndarray'>\n",
      "5850 40\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'int'>\n",
      "<class 'list'>\n",
      "<class 'numpy.int32'>\n",
      "<class 'numpy.ndarray'>\n",
      "(5850,) (5850,) (2882,) (2882,)\n"
     ]
    }
   ],
   "source": [
    "m,n=x_test.shape\n",
    "print(m,n)\n",
    "\n",
    "## Converting form and reshaping\n",
    "TestX=x_test\n",
    "TestY=y_test\n",
    "testy=np.reshape(TestY,(m,))\n",
    "\n",
    "## Changing datatypes\n",
    "testx=np.empty((m,),object)\n",
    "for i in range (0,m):\n",
    "    testx[i]=list(int(v) for v in TestX[i])\n",
    "    testy[i]=testy[i].astype(int)\n",
    "\n",
    "## Printing data-types - relevant to transformer input\n",
    "print(type(testx))\n",
    "print(type(testx[m-1][n-1]))\n",
    "print(type(testx[m-1]))\n",
    "print(type(testy[m-1]))\n",
    "print(type(testy))\n",
    "\n",
    "## Converting Train Data and Getting size of data\n",
    "m,n=x_train.shape\n",
    "print(m,n)\n",
    "\n",
    "## Converting form and reshaping\n",
    "TrainX=x_train\n",
    "TrainY=y_train\n",
    "trainy=np.reshape(TrainY,(m,))\n",
    "\n",
    "## Changing datatypes\n",
    "trainx=np.empty((m,),object)\n",
    "for i in range (0,m):\n",
    "    trainx[i]=list(int(v) for v in TrainX[i])\n",
    "    trainy[i]=TrainY[i].astype(int)\n",
    "    \n",
    "## Printing data-types - relevant to transformer input\n",
    "print(type(trainx))\n",
    "print(type(trainx[m-1][n-1]))\n",
    "print(type(trainx[m-1]))\n",
    "print(type(trainy[m-1]))\n",
    "print(type(trainy))\n",
    "print(trainx.shape,trainy.shape,testx.shape,testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5850 Training sequences\n",
      "2882 Validation sequences\n",
      "(5850, 40) (5850,) (2882, 40) (2882,)\n",
      "[[66555220 82848997 74307757 ... 76632829 76182067 76536759]\n",
      " [58426469 93526622 78619963 ... 76979410 77291146 76625397]\n",
      " [67696884 86622284 74212972 ... 76798209 76305320 76921672]\n",
      " ...\n",
      " [51667161 82083933 70051683 ... 76426917 76515367 77237504]\n",
      " [60194973 86584513 73755442 ... 76288536 76679160 76572179]\n",
      " [37773550 82380914 77285467 ... 76695775 76716357 76715684]] [2 5 4 ... 4 3 3] [[58267469 87639717 74628990 ... 76651049 76130339 76840747]\n",
      " [43664056 90898915 76788339 ... 76617147 76909628 76648158]\n",
      " [71226810 94008682 72395024 ... 76720951 76662916 76631770]\n",
      " ...\n",
      " [67036508 87165966 75575103 ... 76740511 76767239 76849115]\n",
      " [45142388 86109893 77484799 ... 76711513 76729097 76740477]\n",
      " [65342397 88234086 63363674 ... 76602925 76645587 76419896]] [7 3 6 ... 7 6 3]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = max_len+1\n",
    "maxlen = 40\n",
    "print(len(trainx), \"Training sequences\")\n",
    "print(len(testx), \"Validation sequences\")\n",
    "\n",
    "## Converting to padded tensor sequence\n",
    "trainx = keras.preprocessing.sequence.pad_sequences(trainx,maxlen=maxlen)\n",
    "testx = keras.preprocessing.sequence.pad_sequences(testx,maxlen=maxlen)\n",
    "print(trainx.shape,trainy.shape,testx.shape,testy.shape)\n",
    "print(trainx,trainy,testx,testy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 30  ## Embedding size for each token\n",
    "num_heads = 6  ## Number of attention heads\n",
    "ff_dim = 30  ## Hidden layer size in feed forward network inside transformer\n",
    "\n",
    "inputs = layers.Input(shape=(maxlen,))\n",
    "embedding_layer = TokenAndPositionEmbedding(maxlen, vocab_size, embed_dim)\n",
    "x = embedding_layer(inputs)\n",
    "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
    "x = transformer_block(x)\n",
    "x = layers.GlobalAveragePooling1D()(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "x = layers.Dense(20, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = model.fit(trainx, trainy, batch_size=100, epochs=100, validation_data=(testx,testy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
